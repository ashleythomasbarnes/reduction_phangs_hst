{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6686a73-f32a-447f-abf9-2754b1013b6c",
   "metadata": {},
   "source": [
    "# User defined inputs - please update as instructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aab5289a-2567-4fa0-a2c7-14e0bab45a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"In this code block, you only need to update the values for the variables galaxy, \n",
    "  halpha_inputfilename, cont2_inputfilename, cont1_inputfilename, \n",
    "  and input_muse_filename to match your specific requirements.\"\"\"\n",
    "\n",
    "# User Input: Define the galaxy\n",
    "galaxy = 'ngc628'\n",
    "\n",
    "# User Input: Define input files for continuum subtraction\n",
    "halpha_inputfilename = '../hst_cropped/ngc628_acs_wfc_f658n_sci_regrid_shifted.fits'\n",
    "cont2_inputfilename = '../hst_cropped/ngc628_acs_f814w_exp_drc_sci.fits'\n",
    "cont1_inputfilename = '../hst_cropped/ngc628_uvis_f555w_exp_drc_sci.fits'\n",
    "\n",
    "# User Input: Define input files for flux postprocessing\n",
    "input_muse_filename = '/Users/abarnes/Dropbox/work/Projects/pressures/phangs/data/maps/muse/NGC0628-0.92asec_MAPS.fits'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8a2cc5-b677-49a0-bf61-6b554ca784d5",
   "metadata": {},
   "source": [
    "# The following should run automatically with little/no user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc9ed47b-47bc-498f-9b49-085a12d5e01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import astropy.units as u\n",
    "from astropy.io import fits\n",
    "from reduction_phangs_hst import contsub, contsub_misc, contsub_postprocess\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20023c66-701f-463b-9b49-642dcf7b5faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory './f555w_f814w/' already exists.\n",
      "[INFO] Loading Continuum 1: ../hst_cropped/ngc628_uvis_f555w_exp_drc_sci.fits\n",
      "[INFO] Loading Emission Line Image: ../hst_cropped/ngc628_acs_wfc_f658n_sci_regrid_shifted.fits\n",
      "[INFO] Loading Continuum 2: ../hst_cropped/ngc628_acs_f814w_exp_drc_sci.fits\n",
      "[INFO] Continuum file saved: ./f555w_f814w//ngc628_cont_raw.fits.fits\n"
     ]
    }
   ],
   "source": [
    "# Create output directory for continuum subtraction\n",
    "# The output directory will be named based on the substring extracted from the first and second continuum filenames\n",
    "cont1_substring = contsub_misc.extract_substring(cont1_inputfilename)  # Extract substring from the first continuum filename\n",
    "cont2_substring = contsub_misc.extract_substring(cont2_inputfilename)  # Extract substring from the second continuum filename\n",
    "output_dir = './%s_%s/' % (cont1_substring, cont2_substring)  # Define the output directory path\n",
    "contsub_misc.create_directory(output_dir)  # Create the output directory if it doesn't exist\n",
    "\n",
    "halpha_filename = '%s/%s_halpha_raw.fits' % (output_dir, galaxy)  # Set the output filename for the continuum-subtracted emission line image\n",
    "cont_filename = '%s/%s_cont_raw.fits'  % (output_dir, galaxy)  # Set the output filename for the scaled continuum image\n",
    "\n",
    "# Run continuum subtraction\n",
    "# Perform continuum subtraction on the halpha_inputfilename using the cont1_inputfilename and cont2_inputfilename\n",
    "contsub.continuum_subtraction(halpha_inputfilename, cont1_inputfilename, halpha_filename, cont_filename, cont2_inputfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80826eec-6da7-401a-8b4f-0f07703cb7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./f555w_f814w//ngc628_halpha_raw.fits\n",
      "Scaling the data...\n",
      "Converting units...\n",
      "Saving the processed FITS file as ./f555w_f814w//ngc628_halpha.fits\n"
     ]
    }
   ],
   "source": [
    "# Define the output filename by replacing '_raw.fits' with '.fits'\n",
    "output_filename = halpha_filename.replace('_raw.fits', '.fits')\n",
    "\n",
    "# Process the Halpha units and save the result to the output file\n",
    "hdu_hst = contsub_postprocess.process_halpha_units(halpha_filename, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20b031a0-687c-4f27-afed-8da865a7b0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Halpha MUSE file: /Users/abarnes/Dropbox/work/Projects/pressures/phangs/data/maps/muse/NGC0628-0.92asec_MAPS.fits\n"
     ]
    }
   ],
   "source": [
    "# Define the output MUSE filename using the output directory and galaxy name\n",
    "output_muse_filename = '%s/%s_musehalpha.fits' % (output_dir, galaxy)\n",
    "\n",
    "# Process the Halpha MUSE file and save the result to the output file\n",
    "hdu_muse = contsub_postprocess.process_halpha_muse(input_muse_filename, output_muse_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe7bab4b-e132-4ba3-b479-93dcdfa1a26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Reprojecting the input image to match the template WCS...\n",
      "[INFO] Performing image reprojection...\n",
      "[INFO] Image reprojection complete.\n",
      "[INFO] Scaling the output data to conserve flux with factor 0.04\n",
      "[INFO] Flux scaling complete.\n",
      "[INFO] Saving the reprojected image to: ./f555w_f814w//ngc628_musehalpha_regrid.fits\n",
      "[INFO] Image saved successfully.\n",
      "[INFO] Reprojection process completed.\n"
     ]
    }
   ],
   "source": [
    "# Define the output MUSE regrid filename using the output directory and galaxy name\n",
    "output_muse_filename = '%s/%s_musehalpha_regrid.fits' % (output_dir, galaxy)\n",
    "\n",
    "# Perform regridding of the MUSE data using the HST data and save the result to the output file\n",
    "hdu_muse_regrid = contsub_postprocess.regrid(hdu_muse, hdu_hst, output_muse_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ad3dcff-c2c7-4aa6-b887-a1f9fde4ccc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Smoothing the image with a beam kernel...\n",
      "[INFO] Pixel scale: 0.04 arcsec arcsec\n",
      "[INFO] Initial Resolution: 0.10 arcsec arcsec\n",
      "[INFO] Desired Resolution: 0.92 arcsec arcsec\n",
      "[INFO] Convolution kernel created.\n",
      "[INFO] Performing image convolution...\n",
      "[INFO] Image convolution complete.\n",
      "[INFO] Saving the smoothed image to: ./f555w_f814w//ngc628_halpha_smoothed.fits\n",
      "[INFO] Image saved successfully.\n",
      "[INFO] Smoothing process completed.\n"
     ]
    }
   ],
   "source": [
    "# Set the initial resolution for HST observations\n",
    "initial_resolution = 0.1 * u.arcsec\n",
    "\n",
    "# Extract the resolution substring from the input_muse_filename for the desired resolution\n",
    "desired_resolution = float(contsub_misc.extract_substring(input_muse_filename, pattern=r'\\d+\\.\\d+')) * u.arcsec\n",
    "\n",
    "# Smooth the HST image with the desired beam resolution and save the result to the output file\n",
    "output_filename = halpha_filename.replace('_raw.fits', '_smoothed.fits')\n",
    "hdu_hst_smoothed = contsub_postprocess.smooth_image_with_beam(hdu_hst, initial_resolution, desired_resolution, output_filename=output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b1ed1ae-3759-45e4-a310-871a0143823b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Ratio smoothed image saved as ./f555w_f814w//ngc628_halpha_hstmuseratio.fits\n",
      "[INFO] Anchored HST image saved as ./f555w_f814w//ngc628_halpha_anchored.fits\n"
     ]
    }
   ],
   "source": [
    "# Generate the output filename for the ratio image by replacing '_raw.fits' with '_hstmuseratio.fits'\n",
    "output_ratio_filename = halpha_filename.replace('_raw.fits', '_hstmuseratio.fits')\n",
    "\n",
    "# Generate the output filename for the anchored HST image by replacing '_raw.fits' with '_anchored.fits'\n",
    "output_anchored_filename = halpha_filename.replace('_raw.fits', '_anchored.fits')\n",
    "\n",
    "# Save the ratio image and smoothed HST image, and obtain the resulting HDUs\n",
    "hdu_ratio_smooth, hdu_hst_anchored = contsub_postprocess.save_ratio_smoothed_image(hdu_muse_regrid, hdu_hst, hdu_hst_smoothed, output_ratio_filename, output_anchored_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ce30794-ca00-4e4c-bdf1-baf399aac2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Anchored HST image with negative values processed and saved as ./f555w_f814w//ngc628_halpha_anchored_intnegs.fits\n"
     ]
    }
   ],
   "source": [
    "# Generate the output filename for the anchored HST image with intensity negations\n",
    "output_anchored_filename = halpha_filename.replace('_raw.fits', '_anchored_intnegs.fits')\n",
    "\n",
    "# Process the anchored HST image with intensity negations and save the result to the output file\n",
    "hdu_hst_anchored_intnegs = contsub_postprocess.process_anchored_image(hdu_hst_anchored, output_anchored_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aac78bef-668e-40e3-af78-f63848ad5d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Image with added noise saved as ./f555w_f814w//ngc628_halpha_anchored_wnoise.fits\n",
      "[INFO] Image with added noise saved as ./f555w_f814w//ngc628_halpha_anchored_intnegs_wnoise.fits\n"
     ]
    }
   ],
   "source": [
    "# Generate the output filename for the anchored HST image with added white noise\n",
    "output_filename = halpha_filename.replace('_raw.fits', '_anchored_wnoise.fits')\n",
    "\n",
    "# Add white noise to the anchored HST image and save the result to the output file\n",
    "hdu_ha_hst_anchored_wnoise = contsub_postprocess.add_noise_to_image(hdu_hst_anchored, output_filename)\n",
    "\n",
    "# Generate the output filename for the anchored HST image with intensity negations and added white noise\n",
    "output_filename = halpha_filename.replace('_raw.fits', '_anchored_intnegs_wnoise.fits')\n",
    "\n",
    "# Add white noise to the anchored HST image with intensity negations and save the result to the output file\n",
    "hdu_hst_anchored_intnegs_wnoise = contsub_postprocess.add_noise_to_image(hdu_hst_anchored, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fe1077-f79c-412b-a2a6-8accb261eb73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
