{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T12:22:30.840659Z",
     "iopub.status.busy": "2024-01-09T12:22:30.839455Z",
     "iopub.status.idle": "2024-01-09T12:22:32.589605Z",
     "shell.execute_reply": "2024-01-09T12:22:32.589090Z"
    }
   },
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import astropy.wcs as wcs\n",
    "import astropy.units as u\n",
    "from astropy.convolution import convolve_fft\n",
    "from astropy.stats import mad_std\n",
    "import numpy as np\n",
    "from radio_beam import Beam\n",
    "from reproject import reproject_interp\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.ndimage import binary_dilation\n",
    "from astropy.modeling import models, fitting\n",
    "from astropy.table import Table, vstack \n",
    "from glob import glob \n",
    "from synphot import SpectralElement, units\n",
    "import os\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T12:22:32.592002Z",
     "iopub.status.busy": "2024-01-09T12:22:32.591880Z",
     "iopub.status.idle": "2024-01-09T12:22:32.620070Z",
     "shell.execute_reply": "2024-01-09T12:22:32.619701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/abarnes/Dropbox/work/Smallprojects/galaxies/data_hstha/ngc5068n/muse/NGC5068-1.04asec_UVIS_F555W.fits\n",
      "/Users/abarnes/Dropbox/work/Smallprojects/galaxies/data_hstha/ngc5068n/muse/NGC5068-1.04asec_UVIS_F658N.fits\n",
      "/Users/abarnes/Dropbox/work/Smallprojects/galaxies/data_hstha/ngc5068n/muse/NGC5068-1.04asec_UVIS_F814W.fits\n",
      "/Users/abarnes/Dropbox/work/Smallprojects/galaxies/data_hstha/ngc5068n/muse/NGC5068_starmask.fits\n",
      "/Users/abarnes/Dropbox/work/Smallprojects/galaxies/data_hstha/ngc5068n/muse/NGC5068_nebmask.fits\n",
      "/Users/abarnes/Dropbox/work/Smallprojects/galaxies/data_hstha/ngc5068n/muse/NGC5068-1.04asec_MAPS.fits\n",
      "/Users/abarnes/Dropbox/work/Smallprojects/galaxies/data_hstha/ngc5068n/hst/ngc5068n_uvis_f555w_exp_drc_sci.fits\n",
      "/Users/abarnes/Dropbox/work/Smallprojects/galaxies/data_hstha/ngc5068n/hst/ngc5068n_uvis_f658n_exp_drc_sci.fits\n",
      "/Users/abarnes/Dropbox/work/Smallprojects/galaxies/data_hstha/ngc5068n/hst/ngc5068n_uvis_f814w_exp_drc_sci.fits\n",
      "/Users/abarnes/Dropbox/work/Smallprojects/galaxies/data_hstha/ngc5068n/muse/NGC5068-1.04asec_UVIS_F658N.fits\n"
     ]
    }
   ],
   "source": [
    "def get_hdu(rootdir, filename, hdu_id=0, return_filename=False):\n",
    "    filename_full = glob(rootdir+filename)[0]\n",
    "    if hdu_id == 'all':\n",
    "        hdu = fits.open(filename_full)\n",
    "    else:\n",
    "        hdu = fits.open(filename_full)[hdu_id]\n",
    "    print(filename_full)\n",
    "\n",
    "    if return_filename: \n",
    "        return(hdu, filename_full)\n",
    "    else:  \n",
    "        return(hdu)\n",
    "\n",
    "galaxy = 'ngc5068n'\n",
    "galaxy_muse = 'ngc5068'\n",
    "rootdir = '/Users/abarnes/Dropbox/work/Smallprojects/galaxies/data_hstha/%s/' %galaxy\n",
    "rootdir_bp = '/Users/abarnes/Dropbox/work/Smallprojects/galaxies/data_misc/hst_filters/' \n",
    "\n",
    "narrowband_filter = 'f658n'\n",
    "instrument_f555w  = 'uvis'\n",
    "instrument_f65Xn = 'uvis'\n",
    "instrument_f814w = 'uvis'\n",
    "\n",
    "hdu_muse_f555w  = get_hdu(rootdir, 'muse/%s*_%s_*F555W.fits' %(galaxy_muse.upper(), instrument_f555w.upper()))\n",
    "hdu_muse_f65Xn  = get_hdu(rootdir, 'muse/%s*_%s_*%s.fits' %(galaxy_muse.upper(), instrument_f65Xn.upper(), narrowband_filter.upper()))\n",
    "hdu_muse_f814w  = get_hdu(rootdir, 'muse/%s*_%s_*F814W.fits' %(galaxy_muse.upper(), instrument_f814w.upper()))\n",
    "hdu_muse_stars  = get_hdu(rootdir, 'muse/%s_starmask.fits' %galaxy_muse.upper())\n",
    "hdu_muse_neb    = get_hdu(rootdir, 'muse/%s_nebmask.fits' %galaxy_muse.upper())\n",
    "hdu_muse        = get_hdu(rootdir, 'muse/%s*_MAPS.fits' %galaxy_muse.upper(), 'all')\n",
    "\n",
    "hdu_hst_f555w   = get_hdu(rootdir, 'hst/%s*_%s_*f555w*.fits' %(galaxy, instrument_f555w))\n",
    "hdu_hst_f65Xn   = get_hdu(rootdir, 'hst/%s*_%s_*%s*.fits' %(galaxy, instrument_f65Xn, narrowband_filter))\n",
    "hdu_hst_f814w   = get_hdu(rootdir, 'hst/%s*_%s_*f814w*.fits' %(galaxy, instrument_f814w))\n",
    "\n",
    "hst_res  = 0.1 * u.arcsec\n",
    "_, file_muse_f65Xn = get_hdu(rootdir, 'muse/%s*_%s_*%s.fits' %(galaxy_muse.upper(), instrument_f65Xn.upper(), narrowband_filter.upper()), return_filename=True)\n",
    "muse_res = np.float32(file_muse_f65Xn.split('asec')[0].split('-')[-1]) * u.arcsec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T12:22:32.622006Z",
     "iopub.status.busy": "2024-01-09T12:22:32.621885Z",
     "iopub.status.idle": "2024-01-09T12:22:32.688949Z",
     "shell.execute_reply": "2024-01-09T12:22:32.688614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Outputing to the following:\n",
      "/Users/abarnes/Dropbox/work/Smallprojects/galaxies/data_hstha/ngc5068n/hst_contsub\n"
     ]
    }
   ],
   "source": [
    "def make_paths(rootdir):\n",
    "    \n",
    "    print('[Info] Outputing to the following:')\n",
    "    print(rootdir+'hst_contsub')\n",
    "\n",
    "    if not os.path.isdir(rootdir+'hst_contsub'):\n",
    "        os.mkdir(rootdir+'hst_contsub')  \n",
    "    if not os.path.isdir(rootdir+'hst_contsub/figs'):\n",
    "        os.mkdir(rootdir+'hst_contsub/figs')\n",
    "    os.system('rm -rf '+rootdir+'hst_contsub/*.fits')\n",
    "\n",
    "make_paths(rootdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T12:22:32.690962Z",
     "iopub.status.busy": "2024-01-09T12:22:32.690826Z",
     "iopub.status.idle": "2024-01-09T12:22:33.036970Z",
     "shell.execute_reply": "2024-01-09T12:22:33.036649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/abarnes/Dropbox/work/Smallprojects/galaxies/data_misc/hst_filters/HST_ACS_WFC.F555W.dat\n",
      "/Users/abarnes/Dropbox/work/Smallprojects/galaxies/data_misc/hst_filters/HST_ACS_WFC.F658N.dat\n",
      "/Users/abarnes/Dropbox/work/Smallprojects/galaxies/data_misc/hst_filters/HST_ACS_WFC.F814W.dat\n",
      "/Users/abarnes/Dropbox/work/Smallprojects/galaxies/data_misc/hst_filters/HST_WFC3_UVIS1.F555W.dat\n",
      "/Users/abarnes/Dropbox/work/Smallprojects/galaxies/data_misc/hst_filters/HST_WFC3_UVIS1.F657N.dat\n",
      "/Users/abarnes/Dropbox/work/Smallprojects/galaxies/data_misc/hst_filters/HST_WFC3_UVIS1.F658N.dat\n",
      "/Users/abarnes/Dropbox/work/Smallprojects/galaxies/data_misc/hst_filters/HST_WFC3_UVIS1.F814W.dat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['ACS_F555W', 'ACS_F658N', 'ACS_F814W', 'UVIS_F555W', 'UVIS_F657N', 'UVIS_F658N', 'UVIS_F814W'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_bandpassinfo(files):\n",
    "\n",
    "    files.sort()\n",
    "\n",
    "    bp = {}\n",
    "    for file in files:\n",
    "\n",
    "        print(file)\n",
    "\n",
    "        area = 45238.93416 * units.AREA  # HST\n",
    "        bp_ = SpectralElement.from_file(file)\n",
    "        name = file.split('/')[-1].split('.dat')[0].replace('HST_', '').replace('.F', '_F')\n",
    "        name = name.replace('WFC_', '')\n",
    "        name = name.replace('WFC3_', '')\n",
    "        name = name.replace('UVIS1', 'UVIS')\n",
    "\n",
    "        bp[name] = {'equivwidth': bp_.equivwidth().value, \n",
    "                    'integrate': bp_.integrate().value, \n",
    "                    'rmswidth': bp_.rmswidth().value, \n",
    "                    'photbw': bp_.photbw().value, \n",
    "                    'fwhm': bp_.fwhm().value, \n",
    "                    'rectwidth': bp_.rectwidth().value, \n",
    "                    'pivot': bp_.pivot().value, \n",
    "                    'unit_response': bp_.unit_response(area).value}  \n",
    "    \n",
    "    return(bp)\n",
    "\n",
    "files_bp = glob('%s*.dat' %rootdir_bp)\n",
    "bp = get_bandpassinfo(files_bp)\n",
    "bp.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct units \n",
    "HST -> electron/s to ergcm2sA \n",
    "MUSE - > Jy to ergcm2sA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T12:22:33.039635Z",
     "iopub.status.busy": "2024-01-09T12:22:33.039511Z",
     "iopub.status.idle": "2024-01-09T12:22:37.002965Z",
     "shell.execute_reply": "2024-01-09T12:22:37.002453Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_nanzeros(hdu):\n",
    "    hdu.data[hdu.data == 0] = np.nan\n",
    "    return(hdu)\n",
    "\n",
    "hdu_hst_f555w = get_nanzeros(hdu_hst_f555w)\n",
    "hdu_hst_f65Xn = get_nanzeros(hdu_hst_f65Xn)\n",
    "hdu_hst_f814w = get_nanzeros(hdu_hst_f814w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T12:22:37.005183Z",
     "iopub.status.busy": "2024-01-09T12:22:37.005062Z",
     "iopub.status.idle": "2024-01-09T12:22:38.527101Z",
     "shell.execute_reply": "2024-01-09T12:22:38.526752Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_electrons_2_ergcm2sA(hdu, photflam=None, photplam=None, photbw=None):\n",
    "\n",
    "    data = hdu.data.copy()\n",
    "\n",
    "    if photflam == None: \n",
    "\n",
    "        # Get the necessary header keywords for scaling and conversion\n",
    "        photflam = hdu.header['PHOTFLAM']\n",
    "        photplam = hdu.header['PHOTPLAM']\n",
    "        photbw = hdu.header['PHOTBW']\n",
    "    \n",
    "    # Scale the data using photflam and photbw\n",
    "    data_conv = data * photflam\n",
    "\n",
    "    hdu.data = np.array(data_conv, dtype=np.float32) *1e20\n",
    "    hdu.header['BUNIT'] = ('erg/s/cm2/A/pixel', '1e-20 erg/s/cm2/A')\n",
    "\n",
    "    return(hdu)\n",
    "\n",
    "hdu_hst_f555w = get_electrons_2_ergcm2sA(hdu_hst_f555w, bp['%s_%s' %(instrument_f555w.upper(), 'F555W')]['unit_response'])\n",
    "hdu_hst_f65Xn = get_electrons_2_ergcm2sA(hdu_hst_f65Xn, bp['%s_%s' %(instrument_f65Xn.upper(), narrowband_filter.upper())]['unit_response'])\n",
    "hdu_hst_f814w = get_electrons_2_ergcm2sA(hdu_hst_f814w, bp['%s_%s' %(instrument_f814w.upper(), 'F814W')]['unit_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T12:22:38.529402Z",
     "iopub.status.busy": "2024-01-09T12:22:38.529275Z",
     "iopub.status.idle": "2024-01-09T12:22:38.616025Z",
     "shell.execute_reply": "2024-01-09T12:22:38.615694Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_Jy_2_ergcm2sA(hdu, photplam):\n",
    "\n",
    "    data = hdu.data.copy()\n",
    "    \n",
    "    w = photplam * u.AA\n",
    "    a = 1. * u.Jy\n",
    "    b = a.to(u.erg / u.cm**2 / u.s / u.AA, u.spectral_density(w))\n",
    "    data_conv = data * b.value\n",
    "\n",
    "    hdu.data = np.array(data_conv, dtype=np.float32) *1e20\n",
    "    hdu.header['BUNIT'] = ('erg/s/cm2/A/pixel', '1e-20 erg/s/cm2/A')\n",
    "\n",
    "    return(hdu)\n",
    "\n",
    "hdu_muse_f555w = get_Jy_2_ergcm2sA(hdu_muse_f555w, bp['%s_%s' %(instrument_f555w.upper(), 'F555W')]['pivot'])\n",
    "hdu_muse_f65Xn = get_Jy_2_ergcm2sA(hdu_muse_f65Xn, bp['%s_%s' %(instrument_f65Xn.upper(), narrowband_filter.upper())]['pivot'])\n",
    "hdu_muse_f814w = get_Jy_2_ergcm2sA(hdu_muse_f814w, bp['%s_%s' %(instrument_f814w.upper(), 'F814W')]['pivot'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothing and Regridding\n",
    "Smoothing and regridding HST to MUSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T12:22:38.618207Z",
     "iopub.status.busy": "2024-01-09T12:22:38.618094Z",
     "iopub.status.idle": "2024-01-09T12:26:22.415615Z",
     "shell.execute_reply": "2024-01-09T12:26:22.411648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Pixel scale: 0.04 arcsec arcsec\n",
      "[INFO] Initial Resolution: 0.10 arcsec arcsec\n",
      "[INFO] Desired Resolution: 1.04 arcsec arcsec\n",
      "[INFO] Convolution kernel: 1.04 arcsec arcsec\n",
      "[INFO] Performing image convolution...\n",
      "[INFO] Image convolution complete.\n",
      "[INFO] Smoothing process completed.\n",
      "[INFO] Pixel scale: 0.04 arcsec arcsec\n",
      "[INFO] Initial Resolution: 0.10 arcsec arcsec\n",
      "[INFO] Desired Resolution: 1.04 arcsec arcsec\n",
      "[INFO] Convolution kernel: 1.04 arcsec arcsec\n",
      "[INFO] Performing image convolution...\n",
      "[INFO] Image convolution complete.\n",
      "[INFO] Smoothing process completed.\n",
      "[INFO] Pixel scale: 0.04 arcsec arcsec\n",
      "[INFO] Initial Resolution: 0.10 arcsec arcsec\n",
      "[INFO] Desired Resolution: 1.04 arcsec arcsec\n",
      "[INFO] Convolution kernel: 1.04 arcsec arcsec\n",
      "[INFO] Performing image convolution...\n",
      "[INFO] Image convolution complete.\n",
      "[INFO] Smoothing process completed.\n"
     ]
    }
   ],
   "source": [
    "def get_smooth(hdu, initial_resolution, desired_resolution):\n",
    "    \n",
    "    # Create a WCS object from the input HDU header\n",
    "    wcs_ = wcs.WCS(hdu.header)\n",
    "\n",
    "    # Calculate the pixel scale in degrees\n",
    "    pixscale = wcs.utils.proj_plane_pixel_area(wcs_.celestial) ** 0.5 * u.deg\n",
    "    print(f\"[INFO] Pixel scale: {pixscale.to('arcsec'):.2f} arcsec\")\n",
    "\n",
    "    # Define the initial and desired beams\n",
    "    initial_beam = Beam(initial_resolution)\n",
    "    desired_beam = Beam(desired_resolution)\n",
    "\n",
    "    print(f\"[INFO] Initial Resolution: {initial_resolution.to('arcsec'):.2f} arcsec\")\n",
    "    print(f\"[INFO] Desired Resolution: {desired_resolution.to('arcsec'):.2f} arcsec\")\n",
    "    \n",
    "    # Create the convolution kernel\n",
    "    convolution_beam = (desired_resolution.to('arcsec')**2 - initial_resolution.to('arcsec')**2)**0.5\n",
    "    convolution_kernel = desired_beam.deconvolve(initial_beam).as_kernel(pixscale)\n",
    "    print(f\"[INFO] Convolution kernel: {convolution_beam.to('arcsec'):.2f} arcsec\")\n",
    "\n",
    "    # Convolve the image with the kernel to smooth it\n",
    "    print(\"[INFO] Performing image convolution...\")\n",
    "    smoothed_data = convolve_fft(hdu.data, convolution_kernel, preserve_nan=True, allow_huge=True)\n",
    "    print(\"[INFO] Image convolution complete.\")\n",
    "\n",
    "    output_hdu = fits.PrimaryHDU(np.array(smoothed_data, dtype=np.float32), hdu.header)\n",
    "\n",
    "    print(\"[INFO] Smoothing process completed.\")\n",
    "    return(output_hdu)\n",
    "\n",
    "hdu_hst_f555w_sm = get_smooth(hdu_hst_f555w, hst_res, muse_res)\n",
    "hdu_hst_f65Xn_sm = get_smooth(hdu_hst_f65Xn, hst_res, muse_res)\n",
    "hdu_hst_f814w_sm = get_smooth(hdu_hst_f814w, hst_res, muse_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T12:26:22.436148Z",
     "iopub.status.busy": "2024-01-09T12:26:22.435382Z",
     "iopub.status.idle": "2024-01-09T12:26:27.502343Z",
     "shell.execute_reply": "2024-01-09T12:26:27.502035Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Reprojecting the input image to match the template WCS...\n",
      "[INFO] Performing image reprojection...\n",
      "[INFO] Image reprojection complete.\n",
      "[INFO] Scaling the output data to conserve flux with factor 25.48\n",
      "[INFO] Flux scaling complete.\n",
      "[INFO] Reprojection process completed.\n",
      "[INFO] Reprojecting the input image to match the template WCS...\n",
      "[INFO] Performing image reprojection...\n",
      "[INFO] Image reprojection complete.\n",
      "[INFO] Scaling the output data to conserve flux with factor 25.48\n",
      "[INFO] Flux scaling complete.\n",
      "[INFO] Reprojection process completed.\n",
      "[INFO] Reprojecting the input image to match the template WCS...\n",
      "[INFO] Performing image reprojection...\n",
      "[INFO] Image reprojection complete.\n",
      "[INFO] Scaling the output data to conserve flux with factor 25.48\n",
      "[INFO] Flux scaling complete.\n",
      "[INFO] Reprojection process completed.\n"
     ]
    }
   ],
   "source": [
    "def get_regrid(hdu_input, hdu_template, output_filename=None, conserve_flux=True, order='bilinear'):\n",
    "\n",
    "    print(\"[INFO] Reprojecting the input image to match the template WCS...\")\n",
    "\n",
    "    # Extract the WCS information from the input and template headers\n",
    "    wcs_input = wcs.WCS(hdu_input.header)\n",
    "    wcs_template = wcs.WCS(hdu_template.header)\n",
    "\n",
    "    # Calculate the pixel scale for input and template images\n",
    "    pixscale_input = wcs.utils.proj_plane_pixel_area(wcs_input.celestial)\n",
    "    pixscale_template = wcs.utils.proj_plane_pixel_area(wcs_template.celestial)\n",
    "\n",
    "    # Reproject the input image to match the template WCS\n",
    "    print(\"[INFO] Performing image reprojection...\")\n",
    "    # data_output = reproject_interp(hdu_input, hdu_template.header, order=0, parallel=True)[0]\n",
    "    # data_output = reproject_interp(hdu_input, hdu_template.header, order=0)[0]\n",
    "    data_output = reproject_interp(hdu_input, hdu_template.header, order=order)[0]\n",
    "    hdu_output = fits.PrimaryHDU(data_output, hdu_template.header)\n",
    "    print(\"[INFO] Image reprojection complete.\")\n",
    "\n",
    "    if conserve_flux:\n",
    "        # Scale the output data to conserve flux \n",
    "        print(f\"[INFO] Scaling the output data to conserve flux with factor {(pixscale_template / pixscale_input):.2f}\")\n",
    "        hdu_output.data = hdu_output.data * (pixscale_template / pixscale_input)\n",
    "        hdu_output.data = np.array(hdu_output.data, dtype=np.float32)\n",
    "        print(\"[INFO] Flux scaling complete.\")\n",
    "\n",
    "    print(\"[INFO] Reprojection process completed.\")\n",
    "    return(hdu_output)\n",
    "\n",
    "hdu_hst_f555w_smre = get_regrid(hdu_hst_f555w_sm, hdu_muse_f555w)\n",
    "hdu_hst_f65Xn_smre = get_regrid(hdu_hst_f65Xn_sm, hdu_muse_f65Xn)\n",
    "hdu_hst_f814w_smre = get_regrid(hdu_hst_f814w_sm, hdu_muse_f814w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flux scaling\n",
    "Scaling flux of HST to MUSE with linear fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T12:26:27.506052Z",
     "iopub.status.busy": "2024-01-09T12:26:27.505937Z",
     "iopub.status.idle": "2024-01-09T12:26:41.311382Z",
     "shell.execute_reply": "2024-01-09T12:26:41.310974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] xy-fit --- slope: 0.9, intercept: -11.0, intercept scaled:  -0.4\n",
      "[INFO] xy-fit --- slope: 0.9, intercept: 7.1, intercept scaled:  0.3\n",
      "[INFO] xy-fit --- slope: 1.0, intercept: -5.8, intercept scaled:  -0.2\n"
     ]
    }
   ],
   "source": [
    "def get_anchoring(hdu1, hdu2, hdu3, hdu_stars, filter='', make_plots=True):\n",
    "\n",
    "    hdu1 = hdu1.copy()\n",
    "    hdu2 = hdu2.copy()\n",
    "    hdu3 = hdu3.copy()\n",
    "\n",
    "    data1 = hdu1.data.copy()\n",
    "    data2 = hdu2.data.copy()\n",
    "\n",
    "    # Mask zeros \n",
    "    mask_zero1 = data1==0\n",
    "    mask_zero2 = data2==0\n",
    "    data1[(mask_zero1&mask_zero2)] = np.nan\n",
    "    data2[(mask_zero1&mask_zero2)] = np.nan\n",
    "\n",
    "    # Mask with starmask \n",
    "    mask_stars = hdu_stars.data!=0\n",
    "    data1[mask_stars] = np.nan\n",
    "    data2[mask_stars] = np.nan\n",
    "\n",
    "    # Mask with RMS \n",
    "    rms = mad_std(data1, ignore_nan=True)\n",
    "    # rms = mad_std(data1[data1<rms], ignore_nan=True)\n",
    "    mask_high = data1 > rms*5\n",
    "    mask_low = data1 > rms*1\n",
    "    mask1 = binary_dilation(mask_high, mask=mask_low, iterations=-1)\n",
    "\n",
    "    rms = mad_std(data2, ignore_nan=True)\n",
    "    # rms = mad_std(data2[data2<rms], ignore_nan=True)\n",
    "    mask_high = data2 > rms*5\n",
    "    mask_low = data2 > rms*1\n",
    "    mask2 = binary_dilation(mask_high, mask=mask_low, iterations=-1)\n",
    "\n",
    "    data1[~mask1] = np.nan\n",
    "    data2[~mask2] = np.nan\n",
    "\n",
    "    valid_indices = np.isfinite(data1) & np.isfinite(data2)\n",
    "    x_data = data1[valid_indices]\n",
    "    y_data = data2[valid_indices]\n",
    "\n",
    "    # Mask with STD \n",
    "    # std = 34.1+13.6+2.1\n",
    "    std = 49.73\n",
    "    x_per = np.percentile(x_data, [50-std, 50+std])\n",
    "    y_per = np.percentile(y_data, [50-std, 50+std])\n",
    "\n",
    "    x_mask = (x_data>x_per[0])&(x_data<x_per[1])\n",
    "    y_mask = (y_data>y_per[0])&(y_data<y_per[1])\n",
    "\n",
    "    # Mask with STD \n",
    "    ratio = x_data/y_data\n",
    "    r_mask = (ratio>0.33)&(ratio<3)\n",
    "\n",
    "    x_data_fit = x_data[(x_mask&y_mask&r_mask)]\n",
    "    y_data_fit = y_data[(x_mask&y_mask&r_mask)]\n",
    "\n",
    "    x_data_nofit = x_data[~(x_mask&y_mask&r_mask)]\n",
    "    y_data_nofit = y_data[~(x_mask&y_mask&r_mask)]\n",
    "\n",
    "    # Calculate a line of best fit for the data\n",
    "    # slope, intercept = np.polyfit(x_data, y_data, 1)\n",
    "    model_poly = models.Polynomial1D(degree=1)\n",
    "    fitter_poly = fitting.LinearLSQFitter() \n",
    "    best_fit_poly = fitter_poly(model_poly, x_data_fit, y_data_fit)\n",
    "    intercept, slope = best_fit_poly.parameters\n",
    "\n",
    "    x_fit = np.linspace(np.min(x_data), np.max(x_data), 10000)\n",
    "    y_fit = slope * x_fit + intercept\n",
    "    # print(f\"[INFO] xy-fit --- slope: {slope}, intercept: {intercept}\")\n",
    "\n",
    "    # Extract the WCS information from the input and template headers\n",
    "    wcs1 = wcs.WCS(hdu1.header)\n",
    "    wcs3 = wcs.WCS(hdu3.header)\n",
    "    pixscale1 = wcs.utils.proj_plane_pixel_area(wcs1.celestial)\n",
    "    pixscale3 = wcs.utils.proj_plane_pixel_area(wcs3.celestial)\n",
    "\n",
    "    pixscale_ratio = (pixscale3 / pixscale1)\n",
    "    fit = [filter, slope, intercept, intercept*pixscale_ratio]\n",
    "    print(f\"[INFO] xy-fit --- slope: %0.1f, intercept: %0.1f, intercept scaled:  %0.1f\" %(slope, intercept, intercept*pixscale_ratio))\n",
    "    hdu3.data = (hdu3.data - (intercept*pixscale_ratio)) / slope\n",
    "\n",
    "    if make_plots: \n",
    "\n",
    "        fig = plt.figure(figsize=(10, 5))\n",
    "        ax1 = fig.add_subplot(1, 2, 1)\n",
    "        ax2 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "        for ax in [ax1, ax2]:\n",
    "\n",
    "            ax.scatter(x_data_nofit, y_data_nofit, c='C0', alpha=0.05, s=10)\n",
    "            ax.scatter(x_data_fit, y_data_fit, c='C1', alpha=0.05, s=10)\n",
    "\n",
    "            ax.plot(x_fit, best_fit_poly(x_fit), color='k', linewidth=2, \n",
    "                    linestyle='--', label=f'y = {slope:.2f}x + {intercept:.2g}')\n",
    "            ax.plot(x_fit, x_fit, 'k', linewidth=2, linestyle=':', label=f'y = x')\n",
    "\n",
    "            ax.set_xlabel('Flux density (MUSE) [erg/s/cm-2/A/pix]')\n",
    "            ax.set_ylabel('Flux density (HST smoothed, regrid) [erg/s/cm-2/A/pix]')\n",
    "            ax.legend()\n",
    "            ax.grid(True, ls=':', color='k', alpha=0.2, which='both')\n",
    "\n",
    "        ax2.set_xscale('log')\n",
    "        ax2.set_yscale('log')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(rootdir+'hst_contsub/figs/fit_%s.png' %filter, bbox_inches='tight')\n",
    "        plt.close('all')\n",
    "\n",
    "        fig = plt.figure(figsize=(10, 5))\n",
    "        ax1 = fig.add_subplot(1, 2, 1)\n",
    "        ax2 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "        ax1.imshow(data1, vmin=np.nanpercentile(data1, 0.1), vmax=np.nanpercentile(data1, 99), origin='lower', cmap='inferno')\n",
    "        ax2.imshow(data2, vmin=np.nanpercentile(data2, 0.1), vmax=np.nanpercentile(data2, 99), origin='lower', cmap='inferno')\n",
    "\n",
    "        hdu1.data[hdu1.data==0] = np.nan\n",
    "        mask1 = ~np.isnan(hdu1.data)*1\n",
    "        ax1.contour(mask1, levels=[1], colors='k')\n",
    "\n",
    "        hdu2.data[hdu2.data==0] = np.nan\n",
    "        mask2 = ~np.isnan(hdu2.data)*1\n",
    "        ax2.contour(mask2, levels=[1], colors='k')\n",
    "\n",
    "        ax1.set_yticks([])\n",
    "        ax1.set_xticks([])\n",
    "        ax2.set_yticks([])\n",
    "        ax2.set_xticks([])\n",
    "\n",
    "        bbox = dict(boxstyle='round', fc=\"w\", ec=\"k\")\n",
    "        ax1.text(0.5, 0.95, 'MUSE %s' %filter, transform=ax1.transAxes, va='top', ha='center', bbox=bbox)\n",
    "        ax2.text(0.5, 0.95, 'HST %s' %filter, transform=ax2.transAxes, va='top', ha='center', bbox=bbox)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(rootdir+'hst_contsub/figs/masks_%s.png' %filter, bbox_inches='tight')\n",
    "        plt.close('all')\n",
    "\n",
    "    return(hdu3, fit)\n",
    "\n",
    "hdu_hst_f555w_an, fit_f555w = get_anchoring(hdu_muse_f555w, hdu_hst_f555w_smre, hdu_hst_f555w, hdu_muse_stars, 'f555w')\n",
    "hdu_hst_f65Xn_an, fit_f65Xn = get_anchoring(hdu_muse_f65Xn, hdu_hst_f65Xn_smre, hdu_hst_f65Xn, hdu_muse_stars, narrowband_filter)\n",
    "hdu_hst_f814w_an, fit_f814w = get_anchoring(hdu_muse_f814w, hdu_hst_f814w_smre, hdu_hst_f814w, hdu_muse_stars, 'f814w')\n",
    "\n",
    "fit_f555w.append(galaxy)\n",
    "fit_f65Xn.append(galaxy)\n",
    "fit_f814w.append(galaxy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get ratio plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T12:26:41.314187Z",
     "iopub.status.busy": "2024-01-09T12:26:41.314060Z",
     "iopub.status.idle": "2024-01-09T12:26:41.712298Z",
     "shell.execute_reply": "2024-01-09T12:26:41.711884Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_ratio(hdu_hst, hdu_muse, hdu_muse_stars, filter='', make_plots=True, save_hdu=False):\n",
    "\n",
    "    ratio = fits.PrimaryHDU(hdu_hst.data.copy()/hdu_muse.data.copy(), hdu_muse.header)\n",
    "    ratio.data[~np.isfinite(ratio.data)] = np.nan \n",
    "    mask_stars = hdu_muse_stars.data!=0\n",
    "    ratio.data[mask_stars] = np.nan\n",
    "\n",
    "    if save_hdu: \n",
    "        ratio.writeto('ratio_%s.fits' %filter, overwrite=True)\n",
    "\n",
    "    if make_plots: \n",
    "\n",
    "        fig = plt.figure(figsize=(10, 5))\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "        cmap = plt.cm.get_cmap('turbo', 11)\n",
    "        img = ax.imshow(ratio.data, vmin=0, vmax=2, cmap=cmap, origin='lower')\n",
    "        cax = plt.colorbar(img, ax=ax, pad=0.01)\n",
    "        cax.set_label('%s HST/MUSE' %filter)\n",
    "\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticks([])\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(rootdir+'hst_contsub/figs/ratio_%s.png' %filter, bbox_inches='tight')\n",
    "        plt.close('all')\n",
    "\n",
    "    return(ratio)\n",
    "\n",
    "_ = get_ratio(hdu_hst_f555w_smre, hdu_muse_f555w, hdu_muse_stars, filter='f555w')\n",
    "_ = get_ratio(hdu_hst_f65Xn_smre, hdu_muse_f65Xn, hdu_muse_stars, filter=narrowband_filter)\n",
    "_ = get_ratio(hdu_hst_f814w_smre, hdu_muse_f814w, hdu_muse_stars, filter='f814w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append astropy Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T12:26:41.714934Z",
     "iopub.status.busy": "2024-01-09T12:26:41.714816Z",
     "iopub.status.idle": "2024-01-09T12:26:41.747306Z",
     "shell.execute_reply": "2024-01-09T12:26:41.746919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Appending Table...\n"
     ]
    }
   ],
   "source": [
    "fit_table = Table(np.array([fit_f555w, fit_f65Xn, fit_f814w]), names=['filter', 'slope', 'intercept', 'intercept_scaled', 'galaxy'])\n",
    "\n",
    "try: \n",
    "    print('[INFO] Appending Table...')\n",
    "    fit_table_all = Table.read('./../hstha_pipeline_v2_data/fit_table.fits')\n",
    "    fit_table_all.remove_rows(np.where(fit_table_all['galaxy']==galaxy)[0])\n",
    "    fit_table_all = vstack([fit_table_all,fit_table])\n",
    "    fit_table_all.sort('galaxy')\n",
    "    fit_table_all.write('./../hstha_pipeline_v2_data/fit_table.fits', overwrite=True)\n",
    "    fit_table_all.write('./../hstha_pipeline_v2_data/fit_table.csv', overwrite=True)\n",
    "except: \n",
    "    print('[INFO] Making new Table...')\n",
    "    fit_table.write('./../hstha_pipeline_v2_data/fit_table.fits', overwrite=True)\n",
    "    fit_table.write('./../hstha_pipeline_v2_data/fit_table.csv', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuum subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T12:26:41.749763Z",
     "iopub.status.busy": "2024-01-09T12:26:41.749612Z",
     "iopub.status.idle": "2024-01-09T12:26:46.356623Z",
     "shell.execute_reply": "2024-01-09T12:26:46.355854Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_contsub(hdu_halpha, hdu_cont1, hdu_cont2, \n",
    "                photplam_halpha=None, photplam_cont1=None, photplam_cont2=None):\n",
    "\n",
    "    if photplam_halpha == None:\n",
    "        photplam_halpha = hdu_halpha.header['PHOTPLAM']\n",
    "        photplam_cont1 = hdu_cont1.header['PHOTPLAM']\n",
    "        photplam_cont2 = hdu_cont2.header['PHOTPLAM']\n",
    "\n",
    "    weight_cont1 = abs(photplam_cont2 - photplam_halpha) / abs(photplam_cont1 - photplam_cont2)\n",
    "    weight_cont2 = abs(photplam_cont1 - photplam_halpha) / abs(photplam_cont1 - photplam_cont2)\n",
    "\n",
    "    coef_cont1 = weight_cont1\n",
    "    coef_cont2 = weight_cont2\n",
    "\n",
    "    hdu_cont1.data = hdu_cont1.data * coef_cont1\n",
    "    hdu_cont2.data = hdu_cont2.data * coef_cont2\n",
    "\n",
    "    data_cont = hdu_cont1.data + hdu_cont2.data\n",
    "\n",
    "    hdu_halpha_cont = hdu_halpha.copy()\n",
    "    hdu_halpha_contsub = hdu_halpha.copy()\n",
    "\n",
    "    hdu_halpha_cont.data = data_cont\n",
    "    hdu_halpha_contsub.data = hdu_halpha.data - data_cont\n",
    "\n",
    "    hdu_halpha_cont.data = np.array(hdu_halpha_cont.data, dtype=np.float32)\n",
    "    hdu_halpha_contsub.data = np.array(hdu_halpha_contsub.data, dtype=np.float32)\n",
    "\n",
    "    return(hdu_halpha_contsub, hdu_halpha_cont)\n",
    "\n",
    "hdu_muse_halpha, hdu_muse_cont = get_contsub(hdu_muse_f65Xn.copy(), \n",
    "                                hdu_muse_f555w.copy(), \n",
    "                                hdu_muse_f814w.copy(), \n",
    "                                bp['%s_%s' %(instrument_f65Xn.upper(), narrowband_filter.upper())]['pivot'], \n",
    "                                bp['%s_%s' %(instrument_f555w.upper(), 'F555W')]['pivot'], \n",
    "                                bp['%s_%s' %(instrument_f814w.upper(), 'F814W')]['pivot'])  \n",
    "\n",
    "hdu_hst_an_halpha, hdu_hst_an_cont = get_contsub(hdu_hst_f65Xn_an.copy(), \n",
    "                                hdu_hst_f555w_an.copy(), \n",
    "                                hdu_hst_f814w_an.copy(), \n",
    "                                bp['%s_%s' %(instrument_f65Xn.upper(), narrowband_filter.upper())]['pivot'], \n",
    "                                bp['%s_%s' %(instrument_f555w.upper(), 'F555W')]['pivot'], \n",
    "                                bp['%s_%s' %(instrument_f814w.upper(), 'F814W')]['pivot'])       \n",
    "\n",
    "hdu_hst_halpha, hdu_hst_cont = get_contsub(hdu_hst_f65Xn.copy(), \n",
    "                                hdu_hst_f555w.copy(), \n",
    "                                hdu_hst_f814w.copy(), \n",
    "                                bp['%s_%s' %(instrument_f65Xn.upper(), narrowband_filter.upper())]['pivot'], \n",
    "                                bp['%s_%s' %(instrument_f555w.upper(), 'F555W')]['pivot'], \n",
    "                                bp['%s_%s' %(instrument_f814w.upper(), 'F814W')]['pivot'])                                                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct units \n",
    "ergcm2sA to ergcm2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T12:26:46.361288Z",
     "iopub.status.busy": "2024-01-09T12:26:46.361078Z",
     "iopub.status.idle": "2024-01-09T12:26:48.549596Z",
     "shell.execute_reply": "2024-01-09T12:26:48.549254Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_ergcm2sA_2_ergcm2s(hdu, photbw):\n",
    "\n",
    "    data = hdu.data.copy()\n",
    "    data_conv = data * photbw\n",
    "    hdu.data = np.array(data_conv, dtype=np.float32)\n",
    "    hdu.header['BUNIT'] = ('erg/s/cm2/pixel', '1e-20 erg/s/cm2')\n",
    "\n",
    "    return(hdu)\n",
    "\n",
    "# hdu_muse_halpha = get_ergcm2sA_2_ergcm2s(hdu_muse_halpha, hdu_hst_f65Xn.header['PHOTBW'])\n",
    "# hdu_hst_an_halpha = get_ergcm2sA_2_ergcm2s(hdu_hst_an_halpha, hdu_hst_f65Xn.header['PHOTBW'])\n",
    "# hdu_hst_halpha = get_ergcm2sA_2_ergcm2s(hdu_hst_halpha, hdu_hst_f65Xn.header['PHOTBW'])\n",
    "\n",
    "# hdu_muse_cont = get_ergcm2sA_2_ergcm2s(hdu_muse_cont, hdu_hst_f65Xn.header['PHOTBW'])\n",
    "# hdu_hst_an_cont = get_ergcm2sA_2_ergcm2s(hdu_hst_an_cont, hdu_hst_f65Xn.header['PHOTBW'])\n",
    "# hdu_hst_cont = get_ergcm2sA_2_ergcm2s(hdu_hst_cont, hdu_hst_f65Xn.header['PHOTBW'])\n",
    "\n",
    "hdu_muse_halpha = get_ergcm2sA_2_ergcm2s(hdu_muse_halpha, bp['%s_%s' %(instrument_f65Xn.upper(), narrowband_filter.upper())]['rectwidth'])\n",
    "hdu_hst_an_halpha = get_ergcm2sA_2_ergcm2s(hdu_hst_an_halpha, bp['%s_%s' %(instrument_f65Xn.upper(), narrowband_filter.upper())]['rectwidth'])\n",
    "hdu_hst_halpha = get_ergcm2sA_2_ergcm2s(hdu_hst_halpha, bp['%s_%s' %(instrument_f65Xn.upper(), narrowband_filter.upper())]['rectwidth'])\n",
    "\n",
    "hdu_muse_cont = get_ergcm2sA_2_ergcm2s(hdu_muse_cont, bp['%s_%s' %(instrument_f65Xn.upper(), narrowband_filter.upper())]['rectwidth'])\n",
    "hdu_hst_an_cont = get_ergcm2sA_2_ergcm2s(hdu_hst_an_cont, bp['%s_%s' %(instrument_f65Xn.upper(), narrowband_filter.upper())]['rectwidth'])\n",
    "hdu_hst_cont = get_ergcm2sA_2_ergcm2s(hdu_hst_cont, bp['%s_%s' %(instrument_f65Xn.upper(), narrowband_filter.upper())]['rectwidth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get contsub plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T12:26:48.553301Z",
     "iopub.status.busy": "2024-01-09T12:26:48.553181Z",
     "iopub.status.idle": "2024-01-09T12:26:49.209748Z",
     "shell.execute_reply": "2024-01-09T12:26:49.209315Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_comp_muse_ha_plot(hdu_muse_ha_contsub, hdu_muse_ha, matched=True):\n",
    "\n",
    "    data1 = hdu_muse_ha_contsub.data\n",
    "    data2 = hdu_muse_ha.data\n",
    "\n",
    "    data1[data1==0] = np.nan\n",
    "    data2[data2==0] = np.nan\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "    if matched: \n",
    "        vmin = np.nanpercentile(data1, 0.1)\n",
    "        vmax = np.nanpercentile(data1, 98)\n",
    "\n",
    "        ax1.imshow(data1, vmin=vmin, vmax=vmax, origin='lower', cmap='inferno')\n",
    "        img = ax2.imshow(data2, vmin=vmin, vmax=vmax, origin='lower', cmap='inferno')\n",
    "\n",
    "    else:\n",
    "\n",
    "        data1 = np.sqrt(data1)\n",
    "        data2 = np.sqrt(data1)\n",
    "\n",
    "        vmin1 = np.nanpercentile(data1, 0.1)\n",
    "        vmax1 = np.nanpercentile(data1, 98)\n",
    "\n",
    "        vmin2 = np.nanpercentile(data2, 0.1)\n",
    "        vmax2 = np.nanpercentile(data2, 98)\n",
    "\n",
    "        ax1.imshow(data1, vmin=vmin1, vmax=vmax1, origin='lower', cmap='inferno')\n",
    "        ax2.imshow(data2, vmin=vmin2, vmax=vmax2, origin='lower', cmap='inferno')\n",
    "\n",
    "    ax1.set_yticks([])\n",
    "    ax1.set_xticks([])\n",
    "    ax2.set_yticks([])\n",
    "    ax2.set_xticks([])\n",
    "\n",
    "    bbox = dict(boxstyle='round', fc=\"w\", ec=\"k\")\n",
    "    ax1.text(0.5, 0.95, 'MUSE Ha contsub', transform=ax1.transAxes, va='top', ha='center', bbox=bbox)\n",
    "    ax2.text(0.5, 0.95, 'MUSE Ha', transform=ax2.transAxes, va='top', ha='center', bbox=bbox)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if matched: \n",
    "        fig.savefig(rootdir+'hst_contsub/figs/comp_muse_ha_matchedcolor.png', bbox_inches='tight')\n",
    "    else: \n",
    "        fig.savefig(rootdir+'hst_contsub/figs/comp_muse_ha.png', bbox_inches='tight')\n",
    "    plt.close('all')\n",
    "\n",
    "    return()\n",
    "\n",
    "_ = get_comp_muse_ha_plot(hdu_muse_halpha, hdu_muse['HA6562_FLUX'], matched=True)\n",
    "_ = get_comp_muse_ha_plot(hdu_muse_halpha, hdu_muse['HA6562_FLUX'], matched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T12:26:49.212106Z",
     "iopub.status.busy": "2024-01-09T12:26:49.211975Z",
     "iopub.status.idle": "2024-01-09T12:27:18.035108Z",
     "shell.execute_reply": "2024-01-09T12:27:18.034765Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_comp_hst_ha_plot(hdu_hst_an_halpha, hdu_hst_halpha, matched=True):\n",
    "\n",
    "    data1 = hdu_hst_an_halpha.data\n",
    "    data2 = hdu_hst_halpha.data\n",
    "\n",
    "    data1[data1==0] = np.nan\n",
    "    data2[data2==0] = np.nan\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "    if matched: \n",
    "        vmin = np.nanpercentile(data1, 0.1)\n",
    "        vmax = np.nanpercentile(data1, 98)\n",
    "\n",
    "        ax1.imshow(data1, vmin=vmin, vmax=vmax, origin='lower', cmap='inferno')\n",
    "        img = ax2.imshow(data2, vmin=vmin, vmax=vmax, origin='lower', cmap='inferno')\n",
    "\n",
    "    else:\n",
    "\n",
    "        vmin1 = np.nanpercentile(data1, 0.1)\n",
    "        vmax1 = np.nanpercentile(data1, 98)\n",
    "\n",
    "        vmin2 = np.nanpercentile(data2, 0.1)\n",
    "        vmax2 = np.nanpercentile(data2, 98)\n",
    "\n",
    "        ax1.imshow(data1, vmin=vmin1, vmax=vmax1, origin='lower', cmap='inferno')\n",
    "        ax2.imshow(data2, vmin=vmin2, vmax=vmax2, origin='lower', cmap='inferno')\n",
    "\n",
    "    ax1.set_yticks([])\n",
    "    ax1.set_xticks([])\n",
    "    ax2.set_yticks([])\n",
    "    ax2.set_xticks([])\n",
    "\n",
    "    bbox = dict(boxstyle='round', fc=\"w\", ec=\"k\")\n",
    "    ax1.text(0.5, 0.95, 'HST Ha contsub anchored', transform=ax1.transAxes, va='top', ha='center', bbox=bbox)\n",
    "    ax2.text(0.5, 0.95, 'MUSE Ha contsub w/o anchored', transform=ax2.transAxes, va='top', ha='center', bbox=bbox)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if matched: \n",
    "        fig.savefig(rootdir+'hst_contsub/figs/comp_hst_ha_matchedcolor.png', bbox_inches='tight', dpi=300)\n",
    "    else: \n",
    "        fig.savefig(rootdir+'hst_contsub/figs/comp_hst_ha.png', bbox_inches='tight', dpi=300)\n",
    "    plt.close('all')\n",
    "\n",
    "    return()\n",
    "\n",
    "_ = get_comp_hst_ha_plot(hdu_hst_an_halpha, hdu_hst_halpha, matched=True)\n",
    "_ = get_comp_hst_ha_plot(hdu_hst_an_halpha, hdu_hst_halpha, matched=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ha flux scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T12:27:18.037998Z",
     "iopub.status.busy": "2024-01-09T12:27:18.037867Z",
     "iopub.status.idle": "2024-01-09T12:27:27.526376Z",
     "shell.execute_reply": "2024-01-09T12:27:27.526008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] xy-fit --- slope: 0.88, intercept: 5.2, intercept scaled:  0.2\n",
      "[INFO] xy-fit --- slope: 0.88, intercept: 5.2, intercept scaled:  0.2\n"
     ]
    }
   ],
   "source": [
    "def get_anchoring_halpha(hdu1, hdu2, hdu3, hdu_neb, filter='', make_plots=True):\n",
    "\n",
    "    hdu1 = hdu1.copy()\n",
    "    hdu2 = hdu2.copy()\n",
    "    hdu3 = hdu3.copy()\n",
    "\n",
    "    data1 = hdu1.data.copy()\n",
    "    data2 = hdu2.data.copy()\n",
    "\n",
    "    # Mask zeros \n",
    "    mask_zero1 = data1==0\n",
    "    mask_zero2 = data2==0\n",
    "    data1[(mask_zero1&mask_zero2)] = np.nan\n",
    "    data2[(mask_zero1&mask_zero2)] = np.nan\n",
    "\n",
    "    # Mask with nebmask \n",
    "    mask_neb = hdu_neb.data==-1\n",
    "    data1[mask_neb] = np.nan\n",
    "    data2[mask_neb] = np.nan\n",
    "\n",
    "    valid_indices = np.isfinite(data1) & np.isfinite(data2)\n",
    "    x_data = data1[valid_indices]\n",
    "    y_data = data2[valid_indices]\n",
    "\n",
    "    # Mask with STD \n",
    "    std = 49.73\n",
    "    # std = 50\n",
    "    # std = 34.1\n",
    "    x_per = np.percentile(x_data, [50-std, 50+std])\n",
    "    y_per = np.percentile(y_data, [50-std, 50+std])\n",
    "    # x_per = np.percentile(x_data, [0, 50+std])\n",
    "    # y_per = np.percentile(y_data, [0, 50+std])\n",
    "    # x_per = np.percentile(x_data, [0, 100])\n",
    "    # y_per = np.percentile(y_data, [0, 100])\n",
    "\n",
    "    x_mask = (x_data>x_per[0])&(x_data<x_per[1])\n",
    "    y_mask = (y_data>y_per[0])&(y_data<y_per[1])\n",
    "\n",
    "    # Mask with STD \n",
    "    # ratio = y_data/x_data\n",
    "    # r_mask = (ratio>0.33)&(ratio<1.5)\n",
    "\n",
    "    x_data_fit = x_data[(x_mask&y_mask)]\n",
    "    y_data_fit = y_data[(x_mask&y_mask)]\n",
    "\n",
    "    x_data_nofit = x_data[~(x_mask&y_mask)]\n",
    "    y_data_nofit = y_data[~(x_mask&y_mask)]\n",
    "\n",
    "    # valid_indices = np.isfinite(data1) & np.isfinite(data2)\n",
    "    # x_data = data1[valid_indices]\n",
    "    # y_data = data2[valid_indices]\n",
    "\n",
    "    # x_data_fit = x_data\n",
    "    # y_data_fit = y_data\n",
    "\n",
    "    # Calculate a line of best fit for the data\n",
    "    # slope, intercept = np.polyfit(x_data, y_data, 1)\n",
    "    model_poly = models.Polynomial1D(degree=1)\n",
    "    fitter_poly = fitting.LinearLSQFitter() \n",
    "    best_fit_poly = fitter_poly(model_poly, x_data_fit, y_data_fit)\n",
    "    intercept, slope = best_fit_poly.parameters\n",
    "\n",
    "    x_fit = np.linspace(np.min(x_data), np.max(x_data), 10000)\n",
    "    y_fit = slope * x_fit + intercept\n",
    "    # print(f\"[INFO] xy-fit --- slope: {slope}, intercept: {intercept}\")\n",
    "\n",
    "    # Extract the WCS information from the input and template headers\n",
    "    wcs1 = wcs.WCS(hdu1.header)\n",
    "    wcs3 = wcs.WCS(hdu3.header)\n",
    "    pixscale1 = wcs.utils.proj_plane_pixel_area(wcs1.celestial)\n",
    "    pixscale3 = wcs.utils.proj_plane_pixel_area(wcs3.celestial)\n",
    "\n",
    "    pixscale_ratio = (pixscale3 / pixscale1)\n",
    "    fit = [filter, slope, intercept, intercept*pixscale_ratio]\n",
    "    print(f\"[INFO] xy-fit --- slope: %0.2f, intercept: %0.1f, intercept scaled:  %0.1f\" %(slope, intercept, intercept*pixscale_ratio))\n",
    "    hdu3.data = (hdu3.data - (intercept*pixscale_ratio)) / slope\n",
    "\n",
    "    if make_plots: \n",
    "\n",
    "        fig = plt.figure(figsize=(10, 5))\n",
    "        ax1 = fig.add_subplot(1, 2, 1)\n",
    "        ax2 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "        for ax in [ax1, ax2]:\n",
    "\n",
    "            ax.scatter(x_data_nofit, y_data_nofit, c='C0', alpha=0.05, s=10)\n",
    "            ax.scatter(x_data_fit, y_data_fit, c='C1', alpha=0.05, s=10)\n",
    "\n",
    "            ax.plot(x_fit, best_fit_poly(x_fit), color='k', linewidth=2, \n",
    "                    linestyle='--', label=f'y = {slope:.2f}x + {intercept:.2g}')\n",
    "            ax.plot(x_fit, x_fit, 'k', linewidth=2, linestyle=':', label=f'y = x')\n",
    "\n",
    "            ax.set_xlabel('Flux density (MUSE) [erg/s/cm-2/A/pix]')\n",
    "            ax.set_ylabel('Flux density (HST smoothed, regrid) [erg/s/cm-2/A/pix]')\n",
    "            ax.legend()\n",
    "            ax.grid(True, ls=':', color='k', alpha=0.2, which='both')\n",
    "\n",
    "        ax2.set_xscale('log')\n",
    "        ax2.set_yscale('log')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(rootdir+'hst_contsub/figs/fit_%s.png' %filter, bbox_inches='tight')\n",
    "        plt.close('all')\n",
    "\n",
    "        fig = plt.figure(figsize=(10, 5))\n",
    "        ax1 = fig.add_subplot(1, 2, 1)\n",
    "        ax2 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "        ax1.imshow(data1, vmin=np.nanpercentile(data1, 0.1), vmax=np.nanpercentile(data1, 99), origin='lower', cmap='inferno')\n",
    "        ax2.imshow(data2, vmin=np.nanpercentile(data2, 0.1), vmax=np.nanpercentile(data2, 99), origin='lower', cmap='inferno')\n",
    "\n",
    "        hdu1.data[hdu1.data==0] = np.nan\n",
    "        mask1 = ~np.isnan(hdu1.data)*1\n",
    "        ax1.contour(mask1, levels=[1], colors='k')\n",
    "\n",
    "        hdu2.data[hdu2.data==0] = np.nan\n",
    "        mask2 = ~np.isnan(hdu2.data)*1\n",
    "        ax2.contour(mask2, levels=[1], colors='k')\n",
    "\n",
    "        ax1.set_yticks([])\n",
    "        ax1.set_xticks([])\n",
    "        ax2.set_yticks([])\n",
    "        ax2.set_xticks([])\n",
    "\n",
    "        bbox = dict(boxstyle='round', fc=\"w\", ec=\"k\")\n",
    "        ax1.text(0.5, 0.95, 'MUSE %s' %filter, transform=ax1.transAxes, va='top', ha='center', bbox=bbox)\n",
    "        ax2.text(0.5, 0.95, 'HST %s' %filter, transform=ax2.transAxes, va='top', ha='center', bbox=bbox)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(rootdir+'hst_contsub/figs/masks_%s.png' %filter, bbox_inches='tight', dpi=300)\n",
    "        plt.close('all')\n",
    "\n",
    "    return(hdu3, fit)\n",
    "\n",
    "hdu_hst_halpha_scaled, _ = get_anchoring_halpha(hdu_muse['HA6562_FLUX'], hdu_muse_halpha, hdu_hst_halpha, hdu_muse_neb, 'an_halpha_neb')\n",
    "hdu_hst_an_halpha_scaled, _ = get_anchoring_halpha(hdu_muse['HA6562_FLUX'], hdu_muse_halpha, hdu_hst_an_halpha, hdu_muse_neb, 'an_halpha_neb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T12:27:27.528666Z",
     "iopub.status.busy": "2024-01-09T12:27:27.528547Z",
     "iopub.status.idle": "2024-01-09T12:28:45.362584Z",
     "shell.execute_reply": "2024-01-09T12:28:45.362125Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Pixel scale: 0.04 arcsec arcsec\n",
      "[INFO] Initial Resolution: 0.10 arcsec arcsec\n",
      "[INFO] Desired Resolution: 1.04 arcsec arcsec\n",
      "[INFO] Convolution kernel: 1.04 arcsec arcsec\n",
      "[INFO] Performing image convolution...\n",
      "[INFO] Image convolution complete.\n",
      "[INFO] Smoothing process completed.\n",
      "[INFO] Reprojecting the input image to match the template WCS...\n",
      "[INFO] Performing image reprojection...\n",
      "[INFO] Image reprojection complete.\n",
      "[INFO] Scaling the output data to conserve flux with factor 25.48\n",
      "[INFO] Flux scaling complete.\n",
      "[INFO] Reprojection process completed.\n",
      "[INFO] Median flux ratio: 0.892\n"
     ]
    }
   ],
   "source": [
    "def plot_flux_submasks(hdu1, hdu2, hdu_neb, filter='', make_plots=True):\n",
    "\n",
    "    data_neb = hdu_neb.data.copy()\n",
    "    ids = np.unique(data_neb)\n",
    "    ids.sort()\n",
    "    ids = ids[1:]\n",
    "\n",
    "    flux_1 = np.ones(len(ids))\n",
    "    flux_2 = np.ones(len(ids))\n",
    "\n",
    "    for i in range(len(ids)): \n",
    "        mask = data_neb == ids[i]\n",
    "        flux_1[i] = np.nansum(hdu1.data[mask])\n",
    "        flux_2[i] = np.nansum(hdu2.data[mask])\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.scatter(flux_2[flux_2!=0], flux_2[flux_2!=0]/flux_1[flux_2!=0], fc='none', ec='C0')\n",
    "    ax.set_ylim(0.7, 1.3)\n",
    "    ax.set_xscale('log')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(rootdir+'hst_contsub/figs/flux_nebmasks_%s.png' %filter, bbox_inches='tight', dpi=300)\n",
    "    plt.close('all')\n",
    "\n",
    "    median = np.nanmedian(flux_2[flux_2!=0]/flux_1[flux_2!=0])\n",
    "    print('[INFO] Median flux ratio: %0.3f' %(median))\n",
    "\n",
    "hdu_hst_an_halpha_scaled_sm = get_smooth(hdu_hst_an_halpha_scaled, hst_res, muse_res)\n",
    "hdu_hst_an_halpha_scaled_smre = get_regrid(hdu_hst_an_halpha_scaled_sm, hdu_muse_f555w)\n",
    "\n",
    "plot_flux_submasks(hdu_muse['HA6562_FLUX'], hdu_hst_an_halpha_scaled_smre, hdu_muse_neb, filter='an_halpha_neb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving .fits files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T12:28:45.366976Z",
     "iopub.status.busy": "2024-01-09T12:28:45.366812Z",
     "iopub.status.idle": "2024-01-09T12:28:54.185282Z",
     "shell.execute_reply": "2024-01-09T12:28:54.184922Z"
    }
   },
   "outputs": [],
   "source": [
    "hdu_hst_f555w_smre.writeto(rootdir+'hst_contsub/hdu_hst_f555w_smre.fits', overwrite=True)\n",
    "hdu_hst_f65Xn_smre.writeto(rootdir+'hst_contsub/hdu_hst_%s_smre.fits' %narrowband_filter, overwrite=True)\n",
    "hdu_hst_f814w_smre.writeto(rootdir+'hst_contsub/hdu_hst_f814w_smre.fits', overwrite=True)\n",
    "\n",
    "hdu_hst_f555w.writeto(rootdir+'hst_contsub/hdu_hst_f555w.fits', overwrite=True)\n",
    "hdu_hst_f65Xn.writeto(rootdir+'hst_contsub/hdu_hst_%s.fits' %narrowband_filter, overwrite=True)\n",
    "hdu_hst_f814w.writeto(rootdir+'hst_contsub/hdu_hst_f814w.fits', overwrite=True)\n",
    "\n",
    "hdu_muse_f555w.writeto(rootdir+'hst_contsub/hdu_muse_f555w.fits', overwrite=True)\n",
    "hdu_muse_f65Xn.writeto(rootdir+'hst_contsub/hdu_muse_%s.fits' %narrowband_filter, overwrite=True)\n",
    "hdu_muse_f814w.writeto(rootdir+'hst_contsub/hdu_muse_f814w.fits', overwrite=True)\n",
    "\n",
    "hdu_hst_f555w_an.writeto(rootdir+'hst_contsub/hdu_hst_f555w_an.fits', overwrite=True)\n",
    "hdu_hst_f65Xn_an.writeto(rootdir+'hst_contsub/hdu_hst_%s_an.fits' %narrowband_filter, overwrite=True)\n",
    "hdu_hst_f814w_an.writeto(rootdir+'hst_contsub/hdu_hst_f814w_an.fits', overwrite=True)\n",
    "\n",
    "hdu_muse_halpha.writeto(rootdir+'hst_contsub/hdu_muse_%s_contsub.fits' %narrowband_filter, overwrite=True)\n",
    "hdu_hst_an_halpha.writeto(rootdir+'hst_contsub/hdu_hst_%s_an_contsub.fits' %narrowband_filter, overwrite=True)\n",
    "hdu_hst_halpha.writeto(rootdir+'hst_contsub/hdu_hst_%s_contsub.fits' %narrowband_filter, overwrite=True)\n",
    "\n",
    "hdu_muse_cont.writeto(rootdir+'hst_contsub/hdu_muse_%s_cont.fits' %narrowband_filter, overwrite=True)\n",
    "hdu_hst_an_cont.writeto(rootdir+'hst_contsub/hdu_hst_%s_an_cont.fits' %narrowband_filter, overwrite=True)\n",
    "hdu_hst_cont.writeto(rootdir+'hst_contsub/hdu_hst_%s_cont.fits' %narrowband_filter, overwrite=True)\n",
    "\n",
    "hdu_muse['HA6562_FLUX'].writeto(rootdir+'hst_contsub/hdu_muse_ha.fits', overwrite=True)\n",
    "hdu_hst_halpha_scaled.writeto(rootdir+'hst_contsub/hdu_hst_ha.fits', overwrite=True)\n",
    "hdu_hst_an_halpha_scaled.writeto(rootdir+'hst_contsub/hdu_hst_an_ha.fits', overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
